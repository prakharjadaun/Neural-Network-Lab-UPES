{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Multilayer Perceptron**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the required libraries\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definning the class of the multi layer perceptron\n",
    "\n",
    "class MLP():\n",
    "    # constructor of the mlp class\n",
    "    def __init__(self,alpha,v,w):\n",
    "        self.alpha = alpha\n",
    "        self.v = v\n",
    "        self.w = w\n",
    "    # defining the binary sigmoidal activation function\n",
    "    def sigmoid(self,x):\n",
    "        return 1/(1+np.exp(-x))\n",
    "    \n",
    "    # appending 1 at the index of the argument passed\n",
    "    # we are appending 1 because we are adding bias to the neuron input\n",
    "    def append_bias(self,x):\n",
    "        return np.insert(x,0,1)\n",
    "\n",
    "    # computing the binary sigmoid derivative\n",
    "    def sigmoid_derivative(self,x):\n",
    "        return x*(1-x)\n",
    "\n",
    "    # function to compute the feed forward from input to hidden layer\n",
    "    def feed_forward_input_to_hidden(self,x):\n",
    "        self.z = self.sigmoid(np.matmul(self.v,x))\n",
    "        self.z = self.append_bias(self.z)\n",
    "        return self.z\n",
    "\n",
    "    # function to compute the feedforward from hidden to input layer    \n",
    "    def feedforward_hidden_to_out(self):\n",
    "        self.y = self.sigmoid(np.matmul(self.w,self.z))\n",
    "        return self.y\n",
    "        \n",
    "    # computing the error portion of the output layer\n",
    "    def error_portion(self,t):\n",
    "        self.error_p = (t-self.y)*self.sigmoid_derivative(self.y)\n",
    "        return self.error_p\n",
    "    \n",
    "    # change of weights between hidden and the output layer\n",
    "    def compute_dw(self):\n",
    "        self.dw = self.alpha*(self.error_p*self.z)\n",
    "        return self.dw\n",
    "\n",
    "    # error portion of the hidden layer\n",
    "    def error_portion_hidden(self):\n",
    "        self.error_p_hidden = []\n",
    "        for i in range(1,len(self.z)):\n",
    "            temp = (self.error_p*self.w[i])*self.sigmoid_derivative(self.z[i])\n",
    "            self.error_p_hidden.append(temp)\n",
    "        self.error_p_hidden = np.array(self.error_p_hidden)\n",
    "        return self.error_p_hidden\n",
    "    \n",
    "    # change of weights between the hidden and the input layer\n",
    "    def compute_dv(self,x):\n",
    "        self.dv = []\n",
    "        for i in range(len(self.error_p_hidden)):\n",
    "            temp = self.alpha*self.error_p_hidden[i]*x \n",
    "            self.dv.append(temp)\n",
    "        self.dv = np.array(self.dv)\n",
    "        return self.dv\n",
    "\n",
    "    def weight_update(self):\n",
    "        self.w = self.w + self.dw\n",
    "        self.v = self.v + self.dv\n",
    "        return self.w,self.v\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assigning the learning rate \n",
    "alpha = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.3,  0.6, -0.1],\n",
       "       [ 0.5, -0.3,  0.4]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# assigning the weights of the neuron between the input and hidden layer\n",
    "v = np.array([[0.3,0.6,-0.1],[0.5,-0.3,0.4]])\n",
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.2,  0.4,  0.1])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# assigning the weights of the neuron between the hidden and the output layer\n",
    "w = np.array([-0.2,0.4,0.1])\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP(alpha,v,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating tensors of x and y\n",
    "X = np.array([0,1],dtype=np.float32)\n",
    "T = np.array([1],dtype=np.float32)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 1.], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = model.append_bias(X)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# target values\n",
    "T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.       , 0.549834 , 0.7109495])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. feed forward from input to hidden layer\n",
    "model.feed_forward_input_to_hidden(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5227414361305817"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. feed forward from hidden to output layer\n",
    "model.feedforward_hidden_to_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.11906782], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. computing the error portion \n",
    "# passing the target variable to the function\n",
    "model.error_portion(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.02976695, 0.01636688, 0.0211628 ])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. finding the change of weights : dw\n",
    "model.compute_dw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0117885 ],\n",
       "       [0.00244685]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5. computing the error portion of the hidden layer\n",
    "model.error_portion_hidden()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00294713, 0.        , 0.00294713],\n",
       "       [0.00061171, 0.        , 0.00061171]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6. computing the change of weights between the hidden and the input layer : dv\n",
    "model.compute_dv(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. updating the weights \n",
    "w,v = model.weight_update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.17023305,  0.41636688,  0.1211628 ])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# updated w \n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.30294713,  0.6       , -0.09705287],\n",
       "       [ 0.50061171, -0.3       ,  0.40061171]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# updated v\n",
    "v"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
